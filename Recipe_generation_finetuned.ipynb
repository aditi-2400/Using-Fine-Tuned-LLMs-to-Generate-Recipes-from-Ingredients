{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1728879,"sourceType":"datasetVersion","datasetId":1025978}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.808533Z","iopub.status.idle":"2025-01-24T20:36:19.808847Z","shell.execute_reply":"2025-01-24T20:36:19.808733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.809584Z","iopub.status.idle":"2025-01-24T20:36:19.809951Z","shell.execute_reply":"2025-01-24T20:36:19.809794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets rouge_score sacrebleu evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T00:33:59.393112Z","iopub.execute_input":"2025-01-25T00:33:59.393412Z","iopub.status.idle":"2025-01-25T00:34:02.991901Z","shell.execute_reply.started":"2025-01-25T00:33:59.393392Z","shell.execute_reply":"2025-01-25T00:34:02.991032Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\nRequirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.5.1)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.1.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import datasets, transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import T5Tokenizer\nfrom transformers import T5ForConditionalGeneration","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:58.531689Z","iopub.execute_input":"2025-01-24T20:36:58.532212Z","iopub.status.idle":"2025-01-24T20:37:04.205302Z","shell.execute_reply.started":"2025-01-24T20:36:58.532178Z","shell.execute_reply":"2025-01-24T20:37:04.204600Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset_path = '/kaggle/input/recipenlg/RecipeNLG_dataset.csv'\ndf = pd.read_csv(dataset_path)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.811853Z","iopub.status.idle":"2025-01-24T20:36:19.812243Z","shell.execute_reply":"2025-01-24T20:36:19.812070Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Sampling","metadata":{}},{"cell_type":"code","source":"# Randomly sample 10,000 rows from the train dataset\nsampled_data = df.sample(n=50000, random_state=42)\n\n# Save the sampled dataset\nsampled_data.to_csv(\"sampled_train.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.812948Z","iopub.status.idle":"2025-01-24T20:36:19.813326Z","shell.execute_reply":"2025-01-24T20:36:19.813169Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#compare stringified lists to python lists\nimport ast\nsampled_data['ingredients'] = sampled_data['ingredients'].apply(ast.literal_eval)\nsampled_data['directions'] = sampled_data['directions'].apply(ast.literal_eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.814199Z","iopub.status.idle":"2025-01-24T20:36:19.814554Z","shell.execute_reply":"2025-01-24T20:36:19.814395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#create input output pairs\nsampled_data['input'] = sampled_data['ingredients'].apply(lambda x: \"Ingredients: \" + \", \".join(x))\nsampled_data['output'] = sampled_data['directions'].apply(lambda x: \" \".join(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.815254Z","iopub.status.idle":"2025-01-24T20:36:19.815608Z","shell.execute_reply":"2025-01-24T20:36:19.815453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, test_df = train_test_split(sampled_data,test_size=0.2,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.816275Z","iopub.status.idle":"2025-01-24T20:36:19.816632Z","shell.execute_reply":"2025-01-24T20:36:19.816476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.817519Z","iopub.status.idle":"2025-01-24T20:36:19.817885Z","shell.execute_reply":"2025-01-24T20:36:19.817719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\n# Convert train and test DataFrames to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.818708Z","iopub.status.idle":"2025-01-24T20:36:19.819090Z","shell.execute_reply":"2025-01-24T20:36:19.818915Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"#tokenizing the dataset\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T23:29:28.475504Z","iopub.execute_input":"2025-01-24T23:29:28.475819Z","iopub.status.idle":"2025-01-24T23:29:29.106443Z","shell.execute_reply.started":"2025-01-24T23:29:28.475793Z","shell.execute_reply":"2025-01-24T23:29:29.105756Z"}},"outputs":[{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def tokenize_batch(batch):\n  input_text = batch['input']\n  output_text = batch['output']\n  tokenized_input = tokenizer(input_text, padding='max_length',truncation=True, max_length=512)\n  tokenized_output = tokenizer(output_text, padding='max_length',truncation=True, max_length=512)\n  tokenized_input['labels'] = tokenized_output['input_ids']\n  return tokenized_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.820882Z","iopub.status.idle":"2025-01-24T20:36:19.821332Z","shell.execute_reply":"2025-01-24T20:36:19.821166Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_tokenized = train_dataset.map(tokenize_batch, batched=True)\ntest_tokenized = test_dataset.map(tokenize_batch, batched=True)\n\ntrain_tokenized.save_to_disk(\"tokenized_train_dataset\")\ntest_tokenized.save_to_disk(\"tokenized_test_dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.822302Z","iopub.status.idle":"2025-01-24T20:36:19.822660Z","shell.execute_reply":"2025-01-24T20:36:19.822502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_dataset.column_names)\nprint(test_dataset.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:19.823334Z","iopub.status.idle":"2025-01-24T20:36:19.823717Z","shell.execute_reply":"2025-01-24T20:36:19.823559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_from_disk\n\n# Load tokenized dataset\ntrain_tokenized = load_from_disk(\"tokenized_train_dataset\")\ntest_tokenized = load_from_disk(\"tokenized_test_dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:36:47.831310Z","iopub.execute_input":"2025-01-24T20:36:47.831623Z","iopub.status.idle":"2025-01-24T20:36:48.739547Z","shell.execute_reply.started":"2025-01-24T20:36:47.831594Z","shell.execute_reply":"2025-01-24T20:36:48.738702Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Dataloader to load the data","metadata":{}},{"cell_type":"code","source":"batch_size = 8\ndef collate_fn(batch):\n    # Ensure every element in batch is converted to tensor, but ignore strings (such as tokenized words)\n    #print(f\"First batch item: {batch[0]}\")\n    #return {key: torch.tensor([d[key] for d in batch if isinstance(d[key], (list, int))]) for key in batch[0]}\n    return {\n        'input_ids': torch.tensor([d['input_ids'] for d in batch]),\n        'attention_mask': torch.tensor([d['attention_mask'] for d in batch]),\n        'labels': torch.tensor([d['labels'] for d in batch]),\n    }\n\n# Create DataLoaders\ntrain_dataloader = DataLoader(\n    train_tokenized, batch_size=4, shuffle=True, collate_fn=collate_fn\n)\n\ntest_dataloader = DataLoader(\n    test_tokenized, batch_size=4, shuffle=False, collate_fn=collate_fn\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:37:13.498468Z","iopub.execute_input":"2025-01-24T20:37:13.499093Z","iopub.status.idle":"2025-01-24T20:37:13.504362Z","shell.execute_reply.started":"2025-01-24T20:37:13.499063Z","shell.execute_reply":"2025-01-24T20:37:13.503464Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\noptimizer = torch.optim.AdamW(model.parameters(),lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:37:17.727280Z","iopub.execute_input":"2025-01-24T20:37:17.727567Z","iopub.status.idle":"2025-01-24T20:37:18.308268Z","shell.execute_reply.started":"2025-01-24T20:37:17.727545Z","shell.execute_reply":"2025-01-24T20:37:18.307550Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:37:21.080715Z","iopub.execute_input":"2025-01-24T20:37:21.081079Z","iopub.status.idle":"2025-01-24T20:37:21.374975Z","shell.execute_reply.started":"2025-01-24T20:37:21.081052Z","shell.execute_reply":"2025-01-24T20:37:21.374106Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Fine tuning the t5 model ","metadata":{}},{"cell_type":"code","source":"train_loss = []\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for batch in train_dataloader:\n        optimizer.zero_grad()\n        batch = {key: val.to(device) for key, val in batch.items()}\n        outputs = model(\n            input_ids = batch['input_ids'],\n            attention_mask = batch['attention_mask'],\n            labels = batch['labels']\n        )\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    avg_train_loss=running_loss/len(train_dataloader)\n    train_loss.append(avg_train_loss)\n    print(f'Epoch {epoch+1}/{num_epochs} => Train Loss: {avg_train_loss:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T20:37:24.377744Z","iopub.execute_input":"2025-01-24T20:37:24.378053Z","iopub.status.idle":"2025-01-24T23:27:09.875327Z","shell.execute_reply.started":"2025-01-24T20:37:24.378029Z","shell.execute_reply":"2025-01-24T23:27:09.874334Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 => Train Loss: 0.7226\nEpoch 2/5 => Train Loss: 0.6146\nEpoch 3/5 => Train Loss: 0.5829\nEpoch 4/5 => Train Loss: 0.5625\nEpoch 5/5 => Train Loss: 0.5471\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/fine_tuned_t5\")\ntokenizer.save_pretrained(\"/kaggle/working/fine_tuned_t5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T23:29:35.343906Z","iopub.execute_input":"2025-01-24T23:29:35.344212Z","iopub.status.idle":"2025-01-24T23:29:36.105435Z","shell.execute_reply.started":"2025-01-24T23:29:35.344188Z","shell.execute_reply":"2025-01-24T23:29:36.104402Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fine_tuned_t5/tokenizer_config.json',\n '/kaggle/working/fine_tuned_t5/special_tokens_map.json',\n '/kaggle/working/fine_tuned_t5/spiece.model',\n '/kaggle/working/fine_tuned_t5/added_tokens.json')"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Generating Recipes","metadata":{}},{"cell_type":"code","source":"def generate_recipe(ingredients):\n    input_text = f\"Ingredients: { ', '.join(ingredients)}\"\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    outputs = model.generate(input_ids, max_length=512, num_beams=4, early_stopping=True)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T23:32:43.651205Z","iopub.execute_input":"2025-01-24T23:32:43.651509Z","iopub.status.idle":"2025-01-24T23:32:43.655941Z","shell.execute_reply.started":"2025-01-24T23:32:43.651488Z","shell.execute_reply":"2025-01-24T23:32:43.654988Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"ingredients = ['1 dozen eggs', '1 cup flour', '1 gallon milk', '1 cup sugar', '1 oz baking powder']\nprint(generate_recipe(ingredients))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T23:32:46.813861Z","iopub.execute_input":"2025-01-24T23:32:46.814182Z","iopub.status.idle":"2025-01-24T23:32:47.620605Z","shell.execute_reply.started":"2025-01-24T23:32:46.814154Z","shell.execute_reply":"2025-01-24T23:32:47.619842Z"}},"outputs":[{"name":"stdout","text":"Combine eggs, milk, sugar and baking powder in a bowl. Mix well. Pour into a greased 13 x 9-inch pan. Bake at 350 degrees for 30 minutes.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Evaluating the model","metadata":{}},{"cell_type":"code","source":"#from tdqm import tdqm\ndef model_evaluate(test_dataloader,model,device,tokenizer):\n    model.eval()\n    predictions=[]\n    references=[]\n    for batch in test_dataloader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        reference_texts = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n        with torch.no_grad():\n            outputs = model.generate(input_ids,attention_mask=attention_mask, max_length=512, num_beams=4, early_stopping=True)\n        generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        predictions.extend(generated_texts)\n        references.extend(reference_texts)\n    return predictions,references","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T00:38:55.783466Z","iopub.execute_input":"2025-01-25T00:38:55.783779Z","iopub.status.idle":"2025-01-25T00:38:55.789061Z","shell.execute_reply.started":"2025-01-25T00:38:55.783756Z","shell.execute_reply":"2025-01-25T00:38:55.788074Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import evaluate\nbleu_metric = evaluate.load('sacrebleu')\nrouge_metric = evaluate.load('rouge')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T00:34:49.743884Z","iopub.execute_input":"2025-01-25T00:34:49.744255Z","iopub.status.idle":"2025-01-25T00:34:51.705821Z","shell.execute_reply.started":"2025-01-25T00:34:49.744224Z","shell.execute_reply":"2025-01-25T00:34:51.705175Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb578ada11ee4205b4b0bd9a2a2d2059"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f96a5289da684c9693475b5627dd6fa1"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"def compute_metrics(predictions,references):\n    bleu_score = bleu_metric.compute(predictions=predictions, references=[[ref] for ref in references])\n    rouge_result = rouge_metric.compute(predictions=predictions, references=references)\n    \n    return {\"bleu\": bleu_score['score'], \"rouge\": rouge_result}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T00:37:24.828675Z","iopub.execute_input":"2025-01-25T00:37:24.829379Z","iopub.status.idle":"2025-01-25T00:37:24.833786Z","shell.execute_reply.started":"2025-01-25T00:37:24.829347Z","shell.execute_reply":"2025-01-25T00:37:24.832811Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"predictions,references = model_evaluate(test_dataloader,model,device,tokenizer)\nmetrics = compute_metrics(predictions, references)\nprint(f\"BLEU Score: {metrics['bleu']}\")\nprint(f\"ROUGE Scores: {metrics['rouge']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T00:38:59.428710Z","iopub.execute_input":"2025-01-25T00:38:59.429032Z","iopub.status.idle":"2025-01-25T01:49:34.059342Z","shell.execute_reply.started":"2025-01-25T00:38:59.428983Z","shell.execute_reply":"2025-01-25T01:49:34.058435Z"}},"outputs":[{"name":"stdout","text":"BLEU Score: 7.390968610206515\nROUGE Scores: {'rouge1': 0.34327741972707637, 'rouge2': 0.12411536781680829, 'rougeL': 0.251304755136973, 'rougeLsum': 0.25135184546962785}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# Downloading the model","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\nshutil.make_archive('/kaggle/working/fine_tuned_t5','zip','/kaggle/working/fine_tuned_t5')\nfrom IPython.display import FileLink\n\n# Create a download link for the zipped model\nFileLink(\"/kaggle/working/fine_tuned_t5.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T01:56:04.147847Z","iopub.execute_input":"2025-01-25T01:56:04.148294Z","iopub.status.idle":"2025-01-25T01:56:16.066886Z","shell.execute_reply.started":"2025-01-25T01:56:04.148258Z","shell.execute_reply":"2025-01-25T01:56:16.065837Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fine_tuned_t5.zip","text/html":"<a href='/kaggle/working/fine_tuned_t5.zip' target='_blank'>/kaggle/working/fine_tuned_t5.zip</a><br>"},"metadata":{}}],"execution_count":32}]}